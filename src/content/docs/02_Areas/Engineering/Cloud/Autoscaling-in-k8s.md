---
title: AutoScaling in k8s
desc: Look at autoscaling and it's types
---

Great ğŸ‘ Letâ€™s **add HPA (Horizontal Pod Autoscaler)** to the **existing Deployment (`web`)** and make it **actually work on Kind**.

Iâ€™ll do this in **3 clear parts**:
1ï¸âƒ£ what HPA is (short)
2ï¸âƒ£ prerequisites (VERY important)
3ï¸âƒ£ real HPA YAML + test autoscaling

---

# 1ï¸âƒ£ What HPA does (simple)

**HPA automatically changes the number of Pods** based on metrics (CPU / memory).

Example:

```
CPU low  â†’ 2 pods
CPU high â†’ 5 pods
```

ğŸ“Œ **HPA scales Pods**
âŒ NOT nodes
âŒ NOT containers
âŒ NOT Services

---

# 2ï¸âƒ£ Prerequisite: Metrics Server (required!)

âš ï¸ **HPA will NOT work without metrics-server**

### Check if itâ€™s installed

```bash
kubectl get deployment -n kube-system metrics-server
```

If you see **NotFound**, install it ğŸ‘‡

---

## Install Metrics Server (Kind-compatible)

```bash
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
```

Now patch it for Kind (important):

```bash
kubectl patch deployment metrics-server -n kube-system \
--type=json \
-p='[{"op":"add","path":"/spec/template/spec/containers/0/args/-","value":"--kubelet-insecure-tls"}]'
```

Wait until ready:

```bash
kubectl get pods -n kube-system | grep metrics
```

Verify metrics:

```bash
kubectl top nodes
kubectl top pods -n demo
```

âœ… If this works â†’ HPA will work.

---

# 3ï¸âƒ£ Update Deployment (CPU requests REQUIRED)

âš ï¸ HPA **requires CPU requests**.

### Update `web` Deployment

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web
  namespace: demo
spec:
  replicas: 2
  selector:
    matchLabels:
      app: web
  template:
    metadata:
      labels:
        app: web
    spec:
      containers:
      - name: nginx
        image: nginx
        resources:
          requests:
            cpu: 100m
          limits:
            cpu: 500m
```

Apply:

```bash
kubectl apply -f deployment.yaml
```

---

# 4ï¸âƒ£ Create HPA (actual autoscaling)

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: web-hpa
  namespace: demo
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: web
  minReplicas: 2
  maxReplicas: 5
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 50
```

Apply:

```bash
kubectl apply -f hpa.yaml
```

---

## Verify HPA

```bash
kubectl get hpa -n demo
```

Example output:

```
NAME      REFERENCE        TARGETS   MINPODS   MAXPODS   REPLICAS
web-hpa   Deployment/web   10%/50%   2         5         2
```

---

# 5ï¸âƒ£ Test autoscaling (real test)

Generate load inside the cluster:

```bash
kubectl run load-generator \
  --image=busybox \
  -n demo \
  --restart=Never \
  -- sh -c "while true; do wget -q -O- http://web-service; done"
```

Watch scaling:

```bash
kubectl get hpa -n demo -w
```

```bash
kubectl get pods -n demo -w
```

You should see:

```
2 â†’ 3 â†’ 4 â†’ 5 pods
```

ğŸ‰ **Autoscaling works**

---

# 6ï¸âƒ£ Clean up load test

```bash
kubectl delete pod load-generator -n demo
```

After some time, pods scale **back down**.

---

# ğŸ§  Whatâ€™s happening internally (important)

```
metrics-server
     â†“
HPA Controller (control plane)
     â†“
Deployment replicas updated
     â†“
Pods created/removed on workers
```

ğŸ“Œ HPA itself runs in **control plane**
ğŸ“Œ Pods still run on **worker nodes**

---

# âš ï¸ Common mistakes (you avoided them)

âŒ No CPU requests â†’ HPA fails
âŒ No metrics-server â†’ HPA stuck
âŒ Expecting node scaling â†’ wrong (thatâ€™s Cluster Autoscaler)

---

# âœ… You now know REAL autoscaling

This is **production-grade Kubernetes knowledge**.

---

## Want to go next?

U can:

* ğŸ“ˆ add **memory-based HPA**
* âš¡ show **custom metrics**
* ğŸ§  explain **HPA vs VPA vs CA**
* ğŸ”¥ combine **HPA + Ingress + load test**

